{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lord of the Rings Lore Master\n",
    "\n",
    "This notebook creates a chat bot which is an expert on Lord of the Rings lore. It uses Retrieval Augmented Generation (RAG) on the LotR trilogy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model/Embedding/Vector Store Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select chat model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# select embedding model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# select vector store\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the LotR Trilogy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2582402\n"
     ]
    }
   ],
   "source": [
    "# read the trilogy into a long string\n",
    "trilogy = ''\n",
    "\n",
    "# Load The Fellowship of the Ring\n",
    "with open(\"../data/LotR/FotR.txt\") as f:\n",
    "    trilogy += f.read()\n",
    "\n",
    "# Load The Two Towers\n",
    "with open(\"../data/LotR/TT.txt\") as f:\n",
    "    trilogy += f.read()\n",
    "\n",
    "# Load The Return of the King\n",
    "with open(\"../data/LotR/RotK.txt\") as f:\n",
    "    trilogy += f.read()\n",
    "\n",
    "print(len(trilogy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split trilogy into 3683 chunks.\n"
     ]
    }
   ],
   "source": [
    "# split into chunks of size 1000 with overlap of 200\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "text_chunks = text_splitter.create_documents([trilogy])\n",
    "\n",
    "print(f\"Split trilogy into {len(text_chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n",
      "{'start_index': 26626}\n",
      "993\n",
      "It is probable that the craft of building, as many other crafts beside, was derived from the DÃºnedain\n"
     ]
    }
   ],
   "source": [
    "# print some info about a chunk\n",
    "chunk = text_chunks[40]\n",
    "\n",
    "print(type(chunk))\n",
    "print(chunk.metadata)\n",
    "print(len(chunk.page_content))\n",
    "print(chunk.page_content[:102])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Text Chunks in a Vector Store\n",
    "\n",
    "The text embedding model converts text into vector embeddings which we then save in a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0b6e2a45-dad8-4c4a-9e03-a06d82f5661b', 'e22dea32-3c52-4add-8950-7c1c761d84e2', '5b857347-26c9-49de-9eb0-486106b529b4']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=text_chunks)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexk\\Projects\\.venv\\lib\\site-packages\\langsmith\\client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# load a RAG prompt from LangChain's hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# this prompt expects a question and some context, as seen in this example\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a python class to hold a question/context/answer triplet\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are the retrieval and generation functions\n",
    "\n",
    "def retrieve(state: State):\n",
    "    '''search vector store for context related to question and fill state's context'''\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    state[\"context\"] = retrieved_docs\n",
    "\n",
    "def generate(state: State):\n",
    "    '''add question and context to hub's RAG prompt and invoke llm'''\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    state[\"answer\"] = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is a Palantir?', 'context': [Document(id='196af002-41f4-45ed-b836-fbd52652dd5d', metadata={'start_index': 1465814}, page_content='_Chapter 11_\\n            The PalantÃ\\xadr'), Document(id='1312deb2-151a-44c9-b396-79adb38f9bb2', metadata={'start_index': 1492454}, page_content=\"'Each _palantÃ\\xadr_ replied to each, but all those in Gondor were ever open to the view of Osgiliath. Now it appears that, as the rock of Orthanc has withstood the storms of time, so there the _palantÃ\\xadr_ of that tower has remained. But alone it could do nothing but see small images of things far off and days remote. Very useful, no doubt, that was to Saruman; yet it seems that he was not content. Further and further abroad he gazed, until he cast his gaze upon Barad-dÃ»r. Then he was caught!\\n     'Who knows where the lost Stones of Arnor and Gondor now lie buried, or drowned deep? But one. at least Sauron must have obtained and mastered to his purposes. I guess that it was the Ithil-stone, for he took Minas Ithil long ago and turned it into an evil place: Minas Morgul, it has become.\"), Document(id='eda7de8a-b886-4951-b71a-7554fca9d06e', metadata={'start_index': 1490215}, page_content=\"'What are you saying, Gandalf?' asked Pippin.\\n     'I was just running over some of the Rhymes of Lore in my mind ' answered the wizard. 'Hobbits, I suppose, have forgotten them, even those that they ever knew.'\\n     'No, not all,' said Pippin. 'And we have many of our own, which wouldn't interest you, perhaps. But I have never heard this one. What is it about â€“ the seven stars and seven stones?'\\n     'About the _palantÃ\\xadri_ of the Kings of Old,' said Gandalf.\\n     'And what are they?'\\n     'The name meant _that which looks far away_. The Orthanc-stone was one.'\\n     'Then it was not made, not made' â€“ Pippin hesitated â€“ 'by the Enemy?'\"), Document(id='bdbd4835-4250-46a8-8f54-0ebebf2823a3', metadata={'start_index': 1490791}, page_content=\"'Then it was not made, not made' â€“ Pippin hesitated â€“ 'by the Enemy?'\\n     'No,' said Gandalf. 'Nor by Saruman. It is beyond his art, and beyond Sauron's too. The _palantÃ\\xadri_ came from beyond Westernesse from Eldamar. The Noldor made them. FÃ«anor himself, maybe, wrought them, in days so long ago that the time cannot be measured in years. But there is nothing that Sauron cannot turn to evil uses. Alas for Saruman! It was his downfall, as I now perceive. Perilous to us all are the devices of an art deeper than we possess ourselves. Yet he must bear the blame. Fool! to keep it secret, for his own profit. No word did he ever speak of it to any of the Council. We had not yet given thought to the fate of the _palantÃ\\xadri_ of Gondor in its ruinous wars. By Men they were almost forgotten. Even in Gondor they were a secret known only to a few; in Arnor they were remembered only in a rhyme of lore among the DÃºnedain.'\")]}\n"
     ]
    }
   ],
   "source": [
    "# and here we try it out!\n",
    "my_state = State()\n",
    "my_state[\"question\"] = \"What is a Palantir?\"\n",
    "\n",
    "# retrieve the context and print it out to see what the embedding model focuses on\n",
    "retrieve(my_state)\n",
    "print(my_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Palantir, or _palantír_, is a seeing stone that allows the user to view distant places and events. These stones were created by the Noldor, possibly by Fëanor, and are capable of being misused for evil purposes, as seen with Saruman and Sauron. The term itself means \"that which looks far away.\"\n"
     ]
    }
   ],
   "source": [
    "# now ask the LLM the question with context!\n",
    "generate(my_state)\n",
    "print(my_state[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a Custom Prompt Template to Influence the Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a prompt template \n",
    "elven_sage_template = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \"You are an Elven sage who is an expert on the history of Middle Earth. \\\n",
    "     Use the following pieces of retrieved context to answer the question. \\\n",
    "     If you don't know the answer, just say that you don't know. \\\n",
    "     Make your language sound like it was written by Tolkien.\\\n",
    "     \\nQuestion: {question} \\\n",
    "     \\nContext: {context} \\\n",
    "     \\nAnswer:\")\n",
    "])\n",
    "\n",
    "# make a new generate function with this template\n",
    "def generate_with_template(state: State, template: ChatPromptTemplate):\n",
    "    '''add question and context to hub's RAG prompt and invoke llm'''\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = template.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    state[\"answer\"] = response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, dear seeker of knowledge, the Palantir, or _palantíri_ as it is known in the ancient tongue, is a device of great mystery and power, wrought by the hands of the Noldor in the days of yore, perhaps even by the fabled Fëanor himself. The name itself doth mean \"that which looks far away,\" for these seeing-stones were crafted to perceive the distant realms and the events transpiring therein. \n",
      "\n",
      "Each Palantir is a sphere of great artistry, capable of revealing images of far-off places and times, yet they are not without peril, for the gaze of one may be ensnared by another. Such was the fate of Saruman, who, in his hubris, sought to wield the power of the Orthanc-stone, only to find himself ensnared in the web of Sauron’s malice.\n",
      "\n",
      "In the twilight of the Third Age, these stones became relics of a bygone age, scattered and lost to the annals of time. The remnants of their glory lie buried in the histories of Gondor and Arnor, remembered only in the whispers of lore and the secretive murmurs of the wise. Yet, as Gandalf hath spoken, their very nature is a reminder of the perilous depths of knowledge, for such artifacts of power can be turned to dark purposes if wielded by those unworthy. Thus, the Palantir stands as both a beacon of insight and a harbinger of doom, a testament to the wisdom of ages past and the folly of ambition untempered.\n"
     ]
    }
   ],
   "source": [
    "# let's see how this changes the answer\n",
    "my_state = State()\n",
    "my_state[\"question\"] = \"What is a Palantir?\"\n",
    "\n",
    "# retrieve the context\n",
    "retrieve(my_state)\n",
    "\n",
    "# ask the question with context\n",
    "generate_with_template(my_state, elven_sage_template)\n",
    "print(my_state[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
